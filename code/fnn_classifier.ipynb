{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from math import floor, ceil\n",
    "from pylab import rcParams\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training data\n",
    "\n",
    "features = np.loadtxt('vec_mat_features_icex_src_0.01train.csv',delimiter=\",\")\n",
    "temp_labels = np.loadtxt('vec_mat_clabels_icex_src_0.01train.csv',delimiter=\",\")\n",
    "labels_t = []\n",
    "\n",
    "X_train = preprocessing.scale(features)\n",
    "\n",
    "for l in range(len(temp_labels)):\n",
    "    labels_t.append(str(temp_labels[l]))\n",
    "    \n",
    "labels_t = np.array(labels_t)\n",
    "labels_t = labels_t.ravel()\n",
    "\n",
    "def encode(series): \n",
    "    return pd.get_dummies(series.astype(str))\n",
    "\n",
    "y_train = encode(labels_t)\n",
    "labels = list(y_train.columns.values)\n",
    "\n",
    "y_train = pd.DataFrame.as_matrix(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20,10))\n",
    "#plt.pcolormesh(range(1056), range(4701), X_train, cmap='jet',vmin=-2, vmax=2)\n",
    "plt.plot(range(1056),X_train[0,:])\n",
    "plt.title('Training Data')\n",
    "# set the limits of the plot to the limits of the data\n",
    "#ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import test data\n",
    "\n",
    "X_test = np.loadtxt('vec_mat_features_icex_src_test6.csv',delimiter=\",\")\n",
    "temp_ytest = np.loadtxt('vec_mat_clabels_icex_src_test6.csv',delimiter=\",\")\n",
    "y_test= []\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "for l in range(len(temp_ytest)):\n",
    "    y_test.append(str(temp_ytest[l]))\n",
    "    \n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.ravel()\n",
    "label_test = y_test.ravel()\n",
    "\n",
    "y_test = encode(y_test)\n",
    "y_test = pd.DataFrame.as_matrix(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer; with dropout; 128 node sigmoid; softmax output; x-entropy loss; adam\n",
    "\n",
    "drate_l = [0.1,0.2,0.3,0.4,0.5]\n",
    "n_node_l = [32,64,128,256,512]\n",
    "batch_size_l = [32,64,128,256,512]\n",
    "activation_l = [1,2]\n",
    "lr_l = [0.0001,0.001,0.01,0.1]\n",
    "\n",
    "for d in range(len(drate_l)):\n",
    "    for n in range(len(n_node_l)):\n",
    "        for b in range(len(batch_size_l)):\n",
    "            for a in range(len(activation_l)):\n",
    "                for l in range(len(lr_l)):\n",
    "                    \n",
    "                    drate = drate_l[d]\n",
    "                    n_node = n_node_l[n]\n",
    "                    batch_size = batch_size_l[b]\n",
    "                    lr = lr_l[l]\n",
    "                    \n",
    "                    if a == 0:\n",
    "                        activation = tf.nn.relu\n",
    "                        act = 'relu'\n",
    "                    else:\n",
    "                        activation = tf.nn.sigmoid\n",
    "                        act = 'sigmoid'\n",
    "                            \n",
    "                    model = keras.Sequential([\n",
    "                    keras.layers.Dropout(drate),\n",
    "                    keras.layers.Dense(n_node, activation),\n",
    "                    keras.layers.Dense(95, tf.nn.softmax)])\n",
    "                    \n",
    "                    optimizer = keras.optimizers.Adam(lr)\n",
    "                    \n",
    "                    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    \n",
    "                    model.fit(X_train, y_train, batch_size, epochs=5, verbose=0, validation_split=0.0, validation_data=None, shuffle=True)\n",
    "                    \n",
    "                    test_loss, test_acc = model.evaluate(X_test,y_test,verbose=0)\n",
    "\n",
    "                    print('dropout:', drate, '; n_node:', n_node, '; batch size:', batch_size, '; lr:', lr,'; activation:',act, '; Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "drate = 0.5\n",
    "n_node = 256\n",
    "batch_size = 128\n",
    "activation = tf.nn.sigmoid\n",
    "#loss='kullback_leibler_divergence'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(n_node, activation),\n",
    "    #keras.layers.Dropout(drate),\n",
    "    #keras.layers.Dense(n_node, activation),\n",
    "    #keras.layers.Dropout(drate),\n",
    "    #keras.layers.Dense(n_node, activation),\n",
    "    #keras.layers.Dropout(drate),\n",
    "    #keras.layers.Dense(n_node, activation),\n",
    "    #keras.layers.Dropout(drate),\n",
    "    #keras.layers.Dense(n_node, activation),\n",
    "    keras.layers.Dense(95, tf.nn.softmax)])\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = keras.optimizers.Adam(lr)\n",
    "\n",
    "model.compile(optimizer,loss, metrics=['accuracy'])\n",
    "\n",
    "t = time.time()\n",
    "infdb = model.fit(X_train, y_train, batch_size,verbose = True, epochs=23, validation_split=0.0, validation_data=(X_test,y_test), shuffle=True)\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "train_loss, train_acc = model.evaluate(X_train,y_train)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Training accuracy:', train_acc)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "pred_labels = []\n",
    "for i in np.argmax(predictions, axis=1):\n",
    "    pred_labels.append(labels[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = np.arange(1,24)\n",
    "fig1 = plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.suptitle('SNR = INF')\n",
    "plt.plot(epoch, infdb.history['loss'], label = 'Training')\n",
    "plt.plot(epoch, infdb.history['val_loss'],label = 'Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.axis([1, 23, 0, 4])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, 100.*np.array(infdb.history['acc']),label = 'Training')\n",
    "plt.plot(epoch, 100.*np.array(infdb.history['val_acc']),label = 'Testing')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Percent Accuracy')\n",
    "plt.grid()\n",
    "plt.axis([1, 23, 0, 100])\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "#fig1.savefig('cfnn_INFdb.png')\n",
    "'''\n",
    "fig2 = plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.suptitle('SNR = 10dB')\n",
    "plt.plot(epoch, tendb.history['loss'], label = 'Training')\n",
    "plt.plot(epoch, tendb.history['val_loss'],label = 'Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.axis([1, 23, 0, 4])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, 100.*np.array(tendb.history['acc']),label = 'Training')\n",
    "plt.plot(epoch, 100.*np.array(tendb.history['val_acc']),label = 'Testing')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Percent Accuracy')\n",
    "plt.grid()\n",
    "plt.axis([1, 23, 0, 100])\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "fig2.savefig('cfnn_10db.png')\n",
    "\n",
    "fig3 = plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.suptitle('SNR = 5dB')\n",
    "plt.plot(epoch, fivedb.history['loss'], label = 'Training')\n",
    "plt.plot(epoch, fivedb.history['val_loss'],label = 'Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.axis([1, 23, 0, 4])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, 100.*np.array(fivedb.history['acc']),label = 'Training')\n",
    "plt.plot(epoch, 100.*np.array(fivedb.history['val_acc']),label = 'Testing')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Percent Accuracy')\n",
    "plt.grid()\n",
    "plt.axis([1, 23, 0, 100])\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "fig3.savefig('cfnn_5db.png')\n",
    "\n",
    "fig4 = plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.suptitle('SNR = 0dB')\n",
    "plt.plot(epoch, zerodb.history['loss'], label = 'Training')\n",
    "plt.plot(epoch, zerodb.history['val_loss'],label = 'Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.axis([1, 23, 0, 4])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, 100.*np.array(zerodb.history['acc']),label = 'Training')\n",
    "plt.plot(epoch, 100.*np.array(zerodb.history['val_acc']),label = 'Testing')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Percent Accuracy')\n",
    "plt.grid()\n",
    "plt.axis([1, 23, 0, 100])\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "fig4.savefig('cfnn_0db.png')\n",
    "\n",
    "fig5 = plt.figure()\n",
    "epoch = np.arange(1,24)\n",
    "plt.subplot(1,2,1)\n",
    "plt.suptitle('SNR = -5dB')\n",
    "plt.plot(epoch, mfivedb.history['loss'], label = 'Training')\n",
    "plt.plot(epoch, mfivedb.history['val_loss'],label = 'Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.axis([1, 23, 0, 4])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, 100.*np.array(mfivedb.history['acc']),label = 'Training')\n",
    "plt.plot(epoch, 100.*np.array(mfivedb.history['val_acc']),label = 'Testing')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Percent Accuracy')\n",
    "plt.grid()\n",
    "plt.axis([1, 23, 0, 100])\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "fig5.savefig('cfnn_m5db.png')\n",
    "\n",
    "fig6 = plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.suptitle('SNR = -10dB')\n",
    "plt.plot(epoch, mtendb.history['loss'], label = 'Training')\n",
    "plt.plot(epoch, mtendb.history['val_loss'],label = 'Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.axis([1, 23, 0, 4])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, 100.*np.array(mtendb.history['acc']),label = 'Training')\n",
    "plt.plot(epoch, 100.*np.array(mtendb.history['val_acc']),label = 'Testing')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Percent Accuracy')\n",
    "plt.grid()\n",
    "plt.axis([1, 23, 0, 100])\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "fig6.savefig('cfnn_m10db.png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort output for plotting\n",
    "\n",
    "floaty_test = label_test.astype(np.float)\n",
    "inds = floaty_test.argsort()\n",
    "sorted_y_test = label_test[inds]\n",
    "\n",
    "sorted_y_pred = np.array(pred_labels)[inds]\n",
    "\n",
    "floatlabels = np.array(labels).astype(np.float)\n",
    "sortedlabels = np.sort(floatlabels)\n",
    "sortedclassnames = sortedlabels.astype(np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix to see where prediction errors occur\n",
    "\n",
    "cm = confusion_matrix(sorted_y_test, sorted_y_pred, sortedclassnames)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#np.fill_diagonal(cm, 0)\n",
    "\n",
    "index = np.linspace(3,50,95)\n",
    "index_str = []\n",
    "for i in range(len(index)):\n",
    "    index_str.append(str(index[i]))\n",
    "\n",
    "df_cm = pd.DataFrame(cm)\n",
    "fig1 = plt.figure(figsize = (20,14))\n",
    "sn.heatmap(df_cm,cmap=\"YlGnBu\",xticklabels=sortedclassnames,yticklabels=sortedclassnames,linewidths=.3)\n",
    "plt.xlabel=('True label'),\n",
    "plt.ylabel=('Predicted label')\n",
    "plt.title('SNR = INF')\n",
    "fig1.savefig('cfnn_cm_infdb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
