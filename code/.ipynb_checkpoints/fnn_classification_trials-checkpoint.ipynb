{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class traininghist(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        self.trainingloss = []\n",
    "        self.trainingmape = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, mape = self.model.evaluate(x, y, verbose=0)\n",
    "        self.trainingloss.append(loss)\n",
    "        self.trainingmape.append(mape)\n",
    "        print('Training loss: {}, acc: {}\\n'.format(loss, mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training and testing data\n",
    "\n",
    "features = np.loadtxt('vec_mat_features_icex_src_0.01train_pca999p.csv',delimiter=\",\")\n",
    "temp_labels = np.loadtxt('vec_mat_clabels_icex_src_0.01train.csv',delimiter=\",\")\n",
    "labels_t = []\n",
    "\n",
    "X_train = preprocessing.scale(features)\n",
    "\n",
    "for l in range(len(temp_labels)):\n",
    "    labels_t.append(str(temp_labels[l]))\n",
    "    \n",
    "labels_t = np.array(labels_t)\n",
    "labels_t = labels_t.ravel()\n",
    "\n",
    "def encode(series): \n",
    "    return pd.get_dummies(series.astype(str))\n",
    "\n",
    "y_train = encode(labels_t)\n",
    "labels = list(y_train.columns.values)\n",
    "\n",
    "y_train = pd.DataFrame.as_matrix(y_train)\n",
    "\n",
    "\n",
    "X_test = np.loadtxt('vec_mat_features_icex_src_test2_pca999p.csv',delimiter=\",\")\n",
    "temp_ytest = np.loadtxt('vec_mat_clabels_icex_src_test2.csv',delimiter=\",\")\n",
    "y_test= []\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "for l in range(len(temp_ytest)):\n",
    "    y_test.append(str(temp_ytest[l]))\n",
    "    \n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.ravel()\n",
    "label_test = y_test.ravel()\n",
    "\n",
    "y_test = encode(y_test)\n",
    "y_test = pd.DataFrame.as_matrix(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing\n",
    "\n",
    "drate = 0.5\n",
    "n_node = 256\n",
    "batch_size = 128\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "pc_train=[]\n",
    "pc_test=[]\n",
    "\n",
    "for t in range(1):\n",
    "    print(t)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(units=n_node, activation='sigmoid'),\n",
    "        keras.layers.Dropout(drate),\n",
    "        #keras.layers.Dense(units=n_node, activation='sigmoid'),\n",
    "        #keras.layers.Dropout(drate),\n",
    "        #keras.layers.Dense(units=n_node, activation='sigmoid'),\n",
    "        #keras.layers.Dropout(drate),\n",
    "        #keras.layers.Dense(units=n_node, activation='sigmoid'),\n",
    "        #keras.layers.Dropout(drate),\n",
    "        #keras.layers.Dense(units=n_node, activation='sigmoid'),\n",
    "        #keras.layers.Dropout(drate),\n",
    "        keras.layers.Dense(units=95, activation='softmax')])\n",
    "\n",
    "    lr = 0.001\n",
    "    optimizer = keras.optimizers.Adam(lr)\n",
    "\n",
    "    model.compile(optimizer,loss, metrics=['accuracy'])\n",
    "\n",
    "    filepath = \"temp.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='loss', save_best_only=True, mode='auto',period=1)\n",
    "    reduce = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, mode='auto')\n",
    "    early = keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=15, mode='auto',restore_best_weights=True)\n",
    "\n",
    "    traininghistory = traininghist((X_train,y_train))\n",
    "    callbacks_list = [checkpoint,reduce,early,traininghistory]\n",
    "\n",
    "    infdb = model.fit(X_train, y_train, batch_size,verbose = True, epochs=500, validation_data=(X_test,y_test), shuffle=True, callbacks=callbacks_list)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "    train_loss, train_acc = model.evaluate(X_train,y_train)\n",
    "    \n",
    "    pc_train.append(train_acc)\n",
    "    pc_test.append(test_acc)\n",
    "\n",
    "print('Training acc:', np.mean(pc_train)*100,'+/-', np.std(pc_train)*100)\n",
    "print('Testing acc:', np.mean(pc_test)*100,'+/-', np.std(pc_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "epoch = np.arange(1,len(infdb.history['loss'])+1)\n",
    "fig1 = plt.figure(figsize=(8, 4))\n",
    "plt.suptitle('1-Layer FNN Classification (PEV)',fontsize=20)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epoch, traininghistory.trainingloss, label = 'Training')\n",
    "plt.plot(epoch, infdb.history['val_loss'],label = 'Testing')\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Number',fontsize=20)\n",
    "plt.ylabel('Cross Entropy Loss',fontsize=20)\n",
    "plt.axis([0, len(infdb.history['loss'])+1, 0, 5],fontsize=20)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, 100.*np.array(traininghistory.trainingmape),label = 'Training')\n",
    "plt.plot(epoch, 100.*np.array(infdb.history['val_acc']),label = 'Testing')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Epoch Number',fontsize=20)\n",
    "plt.ylabel('Percent Accuracy',fontsize=20)\n",
    "plt.grid()\n",
    "plt.axis([0, len(infdb.history['loss'])+1, 0, 103],fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.savefig('fnn1l_class_PEV.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
