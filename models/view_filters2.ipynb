{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "import keras\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "def encode(series):\n",
    "    return pd.get_dummies(series.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model = keras.models.load_model('cnnc_norm_new.h5')\n",
    "complete_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output = complete_model.get_layer('conv2d_1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Classification testing\n",
    "features_test = np.loadtxt('vec_mat_features_icex_src_test2_norm.csv',delimiter=\",\")\n",
    "temp_ytest = np.loadtxt('vec_mat_rlabels_icex_src_test2_norm.csv',delimiter=\",\")\n",
    "y_test= []\n",
    "\n",
    "real_test = features_test[:,0::2]\n",
    "imag_test = features_test[:,1::2]\n",
    "X_test = np.zeros((features_test.shape[0],32,32,2))\n",
    "\n",
    "for k in range(features_test.shape[0]):\n",
    "    count = 0\n",
    "    for i in range(32):\n",
    "        for j in range(i,32):\n",
    "            X_test[k,i,j,0] = real_test[k,count]\n",
    "            X_test[k,i,j,1] = imag_test[k,count]\n",
    "            \n",
    "            if i!=j:\n",
    "                X_test[k,j,i,0] = X_test[k,i,j,0]\n",
    "                X_test[k,j,i,1] = -X_test[k,i,j,1]\n",
    "            \n",
    "            count = count + 1\n",
    "\n",
    "#X_test[k,:,:,0] = X_test[k,:,:,0]/np.amax(np.abs(X_test[k,:,:,0]))\n",
    "#X_test[k,:,:,1] = X_test[k,:,:,1]/np.amax(np.abs(X_test[k,:,:,1]))\n",
    "\n",
    "temp_ytest = temp_ytest.ravel()\n",
    "y_test = temp_ytest\n",
    "\n",
    "#for l in range(len(temp_ytest)):\n",
    "#    y_test.append(str(temp_ytest[l]))\n",
    "#\n",
    "#y_test = np.array(y_test)\n",
    "#y_test = y_test.ravel()\n",
    "#label_test = y_test.ravel()\n",
    "#\n",
    "#y_test = encode(y_test)\n",
    "#class_names = list(y_test.columns.values)\n",
    "#y_test = pd.DataFrame.as_matrix(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "#Utility function for displaying filters as images\n",
    "#-------------------------------------------------\n",
    "\n",
    "def deprocess_image(x):\n",
    "    \n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    \n",
    "    return x\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "#Utility function for generating patterns for given layer starting from empty input image and then \n",
    "#applying Stochastic Gradient Ascent for maximizing the response of particular filter in given layer\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "def generate_pattern(model,layer_name, filter_index, size=32):\n",
    "    \n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "    input_img_data = np.random.random((1, size, size, 2))\n",
    "    step = 1.\n",
    "    for i in range(80):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step   \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_pattern_from_out(model,layer_name,act_dist, size=32):\n",
    "    \n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(abs(layer_output-act_dist))\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "    input_img_data = np.random.random((1, size, size, 2))\n",
    "    step = 0.01\n",
    "    lossvec = []\n",
    "    for i in range(150):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data -= grads_value * step   \n",
    "        lossvec.append(loss_value)\n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img),lossvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,lossvec = generate_pattern_from_out(complete_model,'dense_9',33.129262,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(lossvec))\n",
    "print(lossvec[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "for j in range(2):\n",
    "    plt.subplot(1,2,j+1)\n",
    "    plt.imshow(img[:,:,j],cmap='jet',interpolation='hanning')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "for j in range(2):\n",
    "    plt.subplot(1,2,j+1)\n",
    "    plt.imshow(X_test[500,:,:,j],cmap='jet',interpolation='hanning')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters1 = []\n",
    "for f in range(16):\n",
    "    img_loss = generate_pattern(complete_model, 'conv2d_9',f,32)\n",
    "\n",
    "    if img_loss is not None:\n",
    "        filters1.append(img_loss)\n",
    "filters1 = np.array(filters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "for j in range(16):\n",
    "    plt.subplot(4,4,j+1)\n",
    "    plt.imshow(np.sqrt(filters1[j,:,:,0]**2+filters1[j,:,:,1]**2),cmap='jet',interpolation='hanning')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[None,0,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------\n",
    "#Here, I am initializing an InceptionV3 model and making prediction on a test image.\n",
    "#Following which, I am creating a activaton heatmap of the last layer of this model,\n",
    "#which is a mixed layer. This heatmap is then superimposed on the original image.\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "model = complete_model\n",
    "x = X_test[None,0,:,:,:]\n",
    "preds = model.predict(x)\n",
    "print(preds)\n",
    "\n",
    "#985 is the class index for class 'Daisy' in Imagenet dataset on which my model is pre-trained\n",
    "output = model.output\n",
    "last_conv_layer = model.get_layer('conv2d_11')\n",
    "\n",
    "grads = K.gradients(output-10.132, last_conv_layer.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "#2048 is the number of filters/channels in 'mixed10' layer\n",
    "for i in range(256):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.imshow(heatmap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using cv2 to superimpose the heatmap on original image to clearly illustrate activated portion of image\n",
    "img = x[0,:,:,0]\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "#heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "#cv2.imwrite('image_name.jpg', superimposed_img)\n",
    "plt.imshow(superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This python file is used for doing following things:\n",
    "1. Creating training and validation generator using Keras' inbuilt ImageDataGenerator object with image augmentation.\n",
    "2. Training a pre-trained InceptionV3 model.\n",
    "3. Displaying and saving layer activations for first 100 layers on a test image.\n",
    "4. Displaying and saving layer filters for few convolution layers\n",
    "5. Displaying and saving heatmaps for test images.\n",
    "'''\n",
    "\n",
    "\n",
    "#-------------------\n",
    "#Declaring constants\n",
    "#-------------------\n",
    " \n",
    "TRAIN_DIR = \"train\"\n",
    "VALID_DIR = \"validation\"\n",
    "IMG_SIZE = (299, 299, 3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "#Creating train and validation data generator using Keras' ImageDataGenerator module\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(TRAIN_DIR, target_size=(IMG_SIZE[0], IMG_SIZE[1]), batch_size=BATCH_SIZE, class_mode=\"categorical\")\n",
    "val_gen = val_datagen.flow_from_directory(VALID_DIR, target_size=(IMG_SIZE[0], IMG_SIZE[1]), batch_size=BATCH_SIZE, class_mode=\"categorical\")\n",
    "\n",
    "\n",
    "#------------------------------------------\n",
    "#Creating InceptionV3 model and training it\n",
    "#------------------------------------------\n",
    "\n",
    "inp = Input(IMG_SIZE)\n",
    "inception = InceptionV3(include_top=False, weights='imagenet', input_tensor=inp, input_shape=IMG_SIZE, pooling='avg')\n",
    "x = inception.output\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "out = Dense(5, activation='softmax')(x)\n",
    "\n",
    "complete_model = Model(inp, out)\n",
    "\n",
    "complete_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "print (complete_model.summary())\n",
    "\n",
    "history = complete_model.fit_generator(train_gen, steps_per_epoch=92, epochs=10, validation_data=val_gen, verbose=1)\n",
    "print (\"Saving history...\")\n",
    "with open('inceptionv3_histobject', 'wb') as fi:\n",
    "    pickle.dump(history.history, fi)\n",
    "\n",
    "complete_model.save('inceptionv3.h5')\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#Getting outputs for intermediate convolution layers by running prediction on test image\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "layer_outputs = [layer.output for layer in complete_model.layers[:50]]\n",
    "test_image = 'any test image'\n",
    "\n",
    "img = image.load_img(test_image, target_size=(IMG_SIZE[0], IMG_SIZE[1]))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "activation_model = Model(inputs=complete_model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "layer_names = ['conv2d_1', 'activation_1', 'conv2d_4', 'activation_4', 'conv2d_9', 'activation_9']\n",
    "activ_list = [activations[1], activations[3], activations[11], activations[13], activations[18], activations[20]]\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activ_list):\n",
    "    n_features = layer_activation.shape[-1]\n",
    "    size = layer_activation.shape[1]\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    \n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='plasma')\n",
    "    plt.savefig(layer_name+\"_grid.jpg\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#Generating convolution layer filters for intermediate layers using above utility functions\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "layer_name = 'conv2d_4'\n",
    "size = 299\n",
    "margin = 5\n",
    "results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3))\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\n",
    "        horizontal_start = i * size + i * margin\n",
    "        horizontal_end = horizontal_start + size\n",
    "        vertical_start = j * size + j * margin\n",
    "        vertical_end = vertical_start + size\n",
    "        results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img\n",
    "        \n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.savefig(results)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
