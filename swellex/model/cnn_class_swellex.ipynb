{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def encode(series):\n",
    "    return pd.get_dummies(series.astype(str))\n",
    "\n",
    "class traininghist(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        self.trainingloss = []\n",
    "        self.trainingmape = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, mape = self.model.evaluate(x, y, verbose=0)\n",
    "        self.trainingloss.append(loss)\n",
    "        self.trainingmape.append(mape)\n",
    "        print('Training loss: {}, acc: {}\\n'.format(loss, mape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training data\n",
    "\n",
    "features = np.loadtxt('vec_mat_features_swellex_109hz2_lr_0.01train.csv',delimiter=\",\")\n",
    "temp_labels = np.loadtxt('vec_mat_clabels_swellex_109hz2_lr_0.01train.csv',delimiter=\",\")\n",
    "labels_t = []\n",
    "\n",
    "real = features[:,0::2]\n",
    "imag = features[:,1::2]\n",
    "X_train = np.zeros((features.shape[0],21,21,2))\n",
    "\n",
    "for k in range(features.shape[0]):\n",
    "    count = 0\n",
    "    for i in range(21):\n",
    "        for j in range(i,21):\n",
    "            X_train[k,i,j,0] = real[k,count]\n",
    "            X_train[k,i,j,1] = imag[k,count]\n",
    "            \n",
    "            if i!=j:\n",
    "                X_train[k,j,i,0] = X_train[k,i,j,0]\n",
    "                X_train[k,j,i,1] = -X_train[k,i,j,1]\n",
    "            \n",
    "            count = count + 1\n",
    "\n",
    "#X_train[k,:,:,0] = X_train[k,:,:,0]/np.amax(np.abs(X_train[k,:,:,0]))\n",
    "#X_train[k,:,:,1] = X_train[k,:,:,1]/np.amax(np.abs(X_train[k,:,:,1]))\n",
    "\n",
    "\n",
    "for l in range(len(temp_labels)):\n",
    "    labels_t.append(str(temp_labels[l]))\n",
    "\n",
    "labels_t = np.array(labels_t)\n",
    "labels_t = labels_t.ravel()\n",
    "\n",
    "y_train = encode(labels_t)\n",
    "labels = list(y_train.columns.values)\n",
    "\n",
    "y_train = pd.DataFrame.as_matrix(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import test data\n",
    "features_test = np.loadtxt('vec_mat_features_swellex_109hz2_test1.csv',delimiter=\",\")\n",
    "temp_ytest = np.loadtxt('vec_mat_rlabels_swellex_109hz2_test.csv',delimiter=\",\")\n",
    "y_test= []\n",
    "\n",
    "real_test = features_test[:,0::2]\n",
    "imag_test = features_test[:,1::2]\n",
    "X_test = np.zeros((features_test.shape[0],21,21,2))\n",
    "\n",
    "for k in range(features_test.shape[0]):\n",
    "    count = 0\n",
    "    for i in range(21):\n",
    "        for j in range(i,21):\n",
    "            X_test[k,i,j,0] = real_test[k,count]\n",
    "            X_test[k,i,j,1] = imag_test[k,count]\n",
    "            \n",
    "            if i!=j:\n",
    "                X_test[k,j,i,0] = X_test[k,i,j,0]\n",
    "                X_test[k,j,i,1] = -X_test[k,i,j,1]\n",
    "            \n",
    "            count = count + 1\n",
    "\n",
    "#X_test[k,:,:,0] = X_test[k,:,:,0]/np.amax(np.abs(X_test[k,:,:,0]))\n",
    "#X_test[k,:,:,1] = X_test[k,:,:,1]/np.amax(np.abs(X_test[k,:,:,1]))\n",
    "\n",
    "\n",
    "temp_ytest = temp_ytest.ravel()\n",
    "#y_test = (temp_ytest - mu)/sigma_labels\n",
    "y_test = temp_ytest\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "index=np.arange(X_train.shape[0])\n",
    "np.random.shuffle(index)\n",
    "\n",
    "X_train=X_train[index,:,:,:]\n",
    "y_train=y_train[index,:]\n",
    "\n",
    "drate = 0.25\n",
    "n_node = 256\n",
    "batch_size = 128\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "model = keras.Sequential([\n",
    "                          keras.layers.Conv2D(input_shape=(21,21,2), filters=16, kernel_size=3,padding='same',activation='selu',strides=(2,2)),\n",
    "                          keras.layers.BatchNormalization(),\n",
    "                          keras.layers.Dropout(0.5),\n",
    "                          keras.layers.Conv2D(filters=128, kernel_size=5,padding='same',activation='selu',strides=(2,2)),\n",
    "                          keras.layers.BatchNormalization(),\n",
    "                          keras.layers.Dropout(0.5),\n",
    "                          keras.layers.Conv2D(filters=256, kernel_size=5,padding='same',activation='selu',strides=(2,2)),\n",
    "                          keras.layers.BatchNormalization(),\n",
    "                          keras.layers.Dropout(0.5),\n",
    "                          #keras.layers.Conv2D(filters=32, kernel_size=3,padding='same',activation='selu',strides=(2,2)),\n",
    "                          #keras.layers.BatchNormalization(),\n",
    "                          #keras.layers.Dropout(0.5),\n",
    "                          #keras.layers.Conv2D(filters=128, kernel_size=3,padding='same',activation='selu',strides=(2,2)),\n",
    "                          #keras.layers.BatchNormalization(),\n",
    "                          keras.layers.Flatten(),\n",
    "                          keras.layers.Dense(units=n_node, activation='sigmoid'),\n",
    "                          keras.layers.Dropout(drate),\n",
    "                          keras.layers.Dense(units=101, activation='softmax')])\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = keras.optimizers.Adam(lr)\n",
    "\n",
    "model.compile(optimizer,loss, metrics=['accuracy'])\n",
    "\n",
    "filepath = \"temp_cnnc_long_range.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, mode='auto',period=1)\n",
    "reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=75, mode='auto')\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=125, mode='auto',restore_best_weights=True)\n",
    "traininghistory = traininghist((X_train,y_train))\n",
    "callbacks_list = [checkpoint,reduce,traininghistory,early]\n",
    "\n",
    "infdb = model.fit(X_train, y_train, batch_size,verbose = True, epochs=5000, validation_split=0.2, shuffle=True,callbacks=callbacks_list)\n",
    "\n",
    "#Testing\n",
    "\n",
    "train_mae, train_acc = model.evaluate(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('Training accuracy:', train_acc)\n",
    "\n",
    "pred_labels = []\n",
    "for i in np.argmax(predictions, axis=1):\n",
    "    pred_labels.append(float(labels[i]))\n",
    "    \n",
    "#print(np.shape(pred_labels))\n",
    "\n",
    "#Classification acc\n",
    "mae = mean_absolute_error(y_test, pred_labels)\n",
    "diff = abs((np.transpose(pred_labels))-(y_test))\n",
    "error = diff[diff>1]\n",
    "percent_correct = (len(y_test)-len(error))/len(y_test)\n",
    "\n",
    "print('Test mae:', mae)\n",
    "print('Testing percent within 1km:', percent_correct*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
